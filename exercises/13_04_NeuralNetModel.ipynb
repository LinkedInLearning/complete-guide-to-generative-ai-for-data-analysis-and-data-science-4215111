{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAAyfOpBdHtMxj6xdZguWd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REBw-mxfSbh2","executionInfo":{"status":"ok","timestamp":1718478912897,"user_tz":420,"elapsed":8848,"user":{"displayName":"Dan Sullivan","userId":"04950569771201204395"}},"outputId":"aa0d86aa-a6a1-4fde-bfbe-d14cc53231b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","6/6 [==============================] - 1s 46ms/step - loss: 1.0633 - accuracy: 0.5104 - val_loss: 1.0494 - val_accuracy: 0.4792\n","Epoch 2/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9906 - accuracy: 0.6823 - val_loss: 1.0122 - val_accuracy: 0.5625\n","Epoch 3/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9299 - accuracy: 0.7708 - val_loss: 0.9801 - val_accuracy: 0.7083\n","Epoch 4/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.8796 - accuracy: 0.8073 - val_loss: 0.9475 - val_accuracy: 0.7083\n","Epoch 5/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.8301 - accuracy: 0.8177 - val_loss: 0.9185 - val_accuracy: 0.7083\n","Epoch 6/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.7839 - accuracy: 0.8229 - val_loss: 0.8929 - val_accuracy: 0.7083\n","Epoch 7/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.7409 - accuracy: 0.8125 - val_loss: 0.8674 - val_accuracy: 0.7500\n","Epoch 8/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.7003 - accuracy: 0.8073 - val_loss: 0.8492 - val_accuracy: 0.7708\n","Epoch 9/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.6619 - accuracy: 0.8073 - val_loss: 0.8346 - val_accuracy: 0.7708\n","Epoch 10/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.6286 - accuracy: 0.8073 - val_loss: 0.8232 - val_accuracy: 0.7708\n","Epoch 11/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.6001 - accuracy: 0.8125 - val_loss: 0.8161 - val_accuracy: 0.7708\n","Epoch 12/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5721 - accuracy: 0.8229 - val_loss: 0.8066 - val_accuracy: 0.7708\n","Epoch 13/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5486 - accuracy: 0.8177 - val_loss: 0.7960 - val_accuracy: 0.7708\n","Epoch 14/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.5284 - accuracy: 0.8177 - val_loss: 0.7885 - val_accuracy: 0.7708\n","Epoch 15/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5088 - accuracy: 0.8229 - val_loss: 0.7808 - val_accuracy: 0.7708\n","Epoch 16/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4911 - accuracy: 0.8229 - val_loss: 0.7780 - val_accuracy: 0.7708\n","Epoch 17/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.4756 - accuracy: 0.8333 - val_loss: 0.7757 - val_accuracy: 0.7708\n","Epoch 18/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.8385 - val_loss: 0.7696 - val_accuracy: 0.7708\n","Epoch 19/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.8438 - val_loss: 0.7595 - val_accuracy: 0.7708\n","Epoch 20/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4341 - accuracy: 0.8438 - val_loss: 0.7502 - val_accuracy: 0.7708\n","Epoch 21/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8438 - val_loss: 0.7425 - val_accuracy: 0.7708\n","Epoch 22/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8594 - val_loss: 0.7338 - val_accuracy: 0.7708\n","Epoch 23/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4010 - accuracy: 0.8646 - val_loss: 0.7271 - val_accuracy: 0.7708\n","Epoch 24/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8646 - val_loss: 0.7212 - val_accuracy: 0.7708\n","Epoch 25/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3795 - accuracy: 0.8646 - val_loss: 0.7193 - val_accuracy: 0.7708\n","Epoch 26/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8646 - val_loss: 0.7109 - val_accuracy: 0.7708\n","Epoch 27/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.3625 - accuracy: 0.8698 - val_loss: 0.7087 - val_accuracy: 0.7708\n","Epoch 28/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3550 - accuracy: 0.8698 - val_loss: 0.7062 - val_accuracy: 0.7708\n","Epoch 29/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.8698 - val_loss: 0.7002 - val_accuracy: 0.7708\n","Epoch 30/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.3407 - accuracy: 0.8750 - val_loss: 0.6988 - val_accuracy: 0.7708\n","Epoch 31/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.3317 - accuracy: 0.8802 - val_loss: 0.6935 - val_accuracy: 0.7708\n","Epoch 32/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.3249 - accuracy: 0.8750 - val_loss: 0.6876 - val_accuracy: 0.7708\n","Epoch 33/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3197 - accuracy: 0.8750 - val_loss: 0.6859 - val_accuracy: 0.7708\n","Epoch 34/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3124 - accuracy: 0.8750 - val_loss: 0.6837 - val_accuracy: 0.7708\n","Epoch 35/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.8750 - val_loss: 0.6865 - val_accuracy: 0.7708\n","Epoch 36/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8750 - val_loss: 0.6838 - val_accuracy: 0.7500\n","Epoch 37/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2956 - accuracy: 0.8802 - val_loss: 0.6816 - val_accuracy: 0.7708\n","Epoch 38/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2917 - accuracy: 0.8802 - val_loss: 0.6735 - val_accuracy: 0.7708\n","Epoch 39/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2870 - accuracy: 0.8906 - val_loss: 0.6765 - val_accuracy: 0.7500\n","Epoch 40/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2799 - accuracy: 0.8906 - val_loss: 0.6735 - val_accuracy: 0.7500\n","Epoch 41/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2754 - accuracy: 0.8958 - val_loss: 0.6719 - val_accuracy: 0.7708\n","Epoch 42/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2701 - accuracy: 0.8906 - val_loss: 0.6674 - val_accuracy: 0.7708\n","Epoch 43/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2661 - accuracy: 0.8906 - val_loss: 0.6640 - val_accuracy: 0.7500\n","Epoch 44/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.8958 - val_loss: 0.6637 - val_accuracy: 0.7500\n","Epoch 45/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2572 - accuracy: 0.8958 - val_loss: 0.6633 - val_accuracy: 0.7500\n","Epoch 46/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2533 - accuracy: 0.8958 - val_loss: 0.6645 - val_accuracy: 0.7708\n","Epoch 47/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2484 - accuracy: 0.8958 - val_loss: 0.6621 - val_accuracy: 0.7708\n","Epoch 48/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.2456 - accuracy: 0.8958 - val_loss: 0.6594 - val_accuracy: 0.7500\n","Epoch 49/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2425 - accuracy: 0.8958 - val_loss: 0.6692 - val_accuracy: 0.7500\n","Epoch 50/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2376 - accuracy: 0.8958 - val_loss: 0.6657 - val_accuracy: 0.7500\n","Epoch 51/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2355 - accuracy: 0.8958 - val_loss: 0.6693 - val_accuracy: 0.7500\n","Epoch 52/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2313 - accuracy: 0.8958 - val_loss: 0.6694 - val_accuracy: 0.7708\n","Epoch 53/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2271 - accuracy: 0.8958 - val_loss: 0.6632 - val_accuracy: 0.7500\n","Epoch 54/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.8958 - val_loss: 0.6595 - val_accuracy: 0.7708\n","Epoch 55/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2219 - accuracy: 0.8958 - val_loss: 0.6664 - val_accuracy: 0.7500\n","Epoch 56/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2173 - accuracy: 0.8958 - val_loss: 0.6691 - val_accuracy: 0.7500\n","Epoch 57/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2161 - accuracy: 0.8958 - val_loss: 0.6735 - val_accuracy: 0.7500\n","Epoch 58/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2117 - accuracy: 0.9010 - val_loss: 0.6724 - val_accuracy: 0.7500\n","Epoch 59/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2094 - accuracy: 0.9062 - val_loss: 0.6722 - val_accuracy: 0.7500\n","Epoch 60/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2074 - accuracy: 0.9115 - val_loss: 0.6686 - val_accuracy: 0.7500\n","Epoch 61/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2047 - accuracy: 0.9115 - val_loss: 0.6749 - val_accuracy: 0.7708\n","Epoch 62/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.2023 - accuracy: 0.9219 - val_loss: 0.6787 - val_accuracy: 0.7708\n","Epoch 63/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1986 - accuracy: 0.9219 - val_loss: 0.6811 - val_accuracy: 0.7708\n","Epoch 64/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1970 - accuracy: 0.9219 - val_loss: 0.6799 - val_accuracy: 0.7500\n","Epoch 65/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1945 - accuracy: 0.9219 - val_loss: 0.6842 - val_accuracy: 0.7500\n","Epoch 66/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1917 - accuracy: 0.9219 - val_loss: 0.6852 - val_accuracy: 0.7500\n","Epoch 67/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.9219 - val_loss: 0.6875 - val_accuracy: 0.7500\n","Epoch 68/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1882 - accuracy: 0.9219 - val_loss: 0.6851 - val_accuracy: 0.7292\n","Epoch 69/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1853 - accuracy: 0.9219 - val_loss: 0.6847 - val_accuracy: 0.7500\n","Epoch 70/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1839 - accuracy: 0.9271 - val_loss: 0.6885 - val_accuracy: 0.7500\n","Epoch 71/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1811 - accuracy: 0.9271 - val_loss: 0.6864 - val_accuracy: 0.7500\n","Epoch 72/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.6906 - val_accuracy: 0.7708\n","Epoch 73/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1782 - accuracy: 0.9271 - val_loss: 0.6840 - val_accuracy: 0.7500\n","Epoch 74/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1759 - accuracy: 0.9271 - val_loss: 0.6848 - val_accuracy: 0.7500\n","Epoch 75/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1741 - accuracy: 0.9271 - val_loss: 0.6874 - val_accuracy: 0.7292\n","Epoch 76/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1730 - accuracy: 0.9323 - val_loss: 0.6865 - val_accuracy: 0.7292\n","Epoch 77/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1709 - accuracy: 0.9427 - val_loss: 0.6954 - val_accuracy: 0.7292\n","Epoch 78/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1688 - accuracy: 0.9375 - val_loss: 0.6997 - val_accuracy: 0.7500\n","Epoch 79/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1688 - accuracy: 0.9375 - val_loss: 0.6918 - val_accuracy: 0.7500\n","Epoch 80/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9375 - val_loss: 0.6974 - val_accuracy: 0.7500\n","Epoch 81/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1639 - accuracy: 0.9427 - val_loss: 0.6956 - val_accuracy: 0.7500\n","Epoch 82/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9375 - val_loss: 0.6930 - val_accuracy: 0.7500\n","Epoch 83/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1602 - accuracy: 0.9375 - val_loss: 0.6976 - val_accuracy: 0.7500\n","Epoch 84/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1597 - accuracy: 0.9427 - val_loss: 0.6979 - val_accuracy: 0.7500\n","Epoch 85/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1577 - accuracy: 0.9427 - val_loss: 0.7079 - val_accuracy: 0.7500\n","Epoch 86/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1564 - accuracy: 0.9427 - val_loss: 0.7135 - val_accuracy: 0.7500\n","Epoch 87/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1548 - accuracy: 0.9427 - val_loss: 0.7080 - val_accuracy: 0.7500\n","Epoch 88/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.1531 - accuracy: 0.9427 - val_loss: 0.7010 - val_accuracy: 0.7500\n","Epoch 89/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1515 - accuracy: 0.9479 - val_loss: 0.7002 - val_accuracy: 0.7292\n","Epoch 90/100\n","6/6 [==============================] - 0s 18ms/step - loss: 0.1501 - accuracy: 0.9479 - val_loss: 0.7032 - val_accuracy: 0.7292\n","Epoch 91/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1493 - accuracy: 0.9479 - val_loss: 0.7072 - val_accuracy: 0.7500\n","Epoch 92/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1474 - accuracy: 0.9427 - val_loss: 0.7096 - val_accuracy: 0.7500\n","Epoch 93/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1456 - accuracy: 0.9427 - val_loss: 0.7090 - val_accuracy: 0.7500\n","Epoch 94/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1457 - accuracy: 0.9427 - val_loss: 0.7072 - val_accuracy: 0.7292\n","Epoch 95/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1446 - accuracy: 0.9427 - val_loss: 0.7128 - val_accuracy: 0.7500\n","Epoch 96/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1445 - accuracy: 0.9427 - val_loss: 0.7153 - val_accuracy: 0.7500\n","Epoch 97/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.7213 - val_accuracy: 0.7500\n","Epoch 98/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1407 - accuracy: 0.9479 - val_loss: 0.7150 - val_accuracy: 0.7500\n","Epoch 99/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1385 - accuracy: 0.9479 - val_loss: 0.7148 - val_accuracy: 0.7500\n","Epoch 100/100\n","6/6 [==============================] - 0s 18ms/step - loss: 0.1375 - accuracy: 0.9479 - val_loss: 0.7197 - val_accuracy: 0.7500\n","Loss: 0.4270815849304199, Accuracy: 0.8166666626930237\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the dataset\n","data = pd.read_csv('/content/synthetic_iris_like_data.csv')\n","\n","# Separate features and labels\n","X = data.drop(columns=['class']).values\n","y = data['class'].values\n","\n","# One-hot encode the labels\n","y = to_categorical(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(y.shape[1], activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","print(f'Loss: {loss}, Accuracy: {accuracy}')\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the dataset\n","file_path = '/content/synthetic_iris_like_data.csv'\n","data = pd.read_csv(file_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['class']).values\n","y = data['class'].values\n","\n","# One-hot encode the labels\n","y = to_categorical(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(y.shape[1], activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","print(f'Loss: {loss}, Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vz6peXScVbkE","executionInfo":{"status":"ok","timestamp":1718479108535,"user_tz":420,"elapsed":21958,"user":{"displayName":"Dan Sullivan","userId":"04950569771201204395"}},"outputId":"6dd7964a-da37-44d3-ecd1-edf066d945b8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","6/6 [==============================] - 1s 44ms/step - loss: 1.0774 - accuracy: 0.3333 - val_loss: 1.0345 - val_accuracy: 0.5000\n","Epoch 2/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.9994 - accuracy: 0.6719 - val_loss: 0.9914 - val_accuracy: 0.6667\n","Epoch 3/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9153 - accuracy: 0.7812 - val_loss: 0.9336 - val_accuracy: 0.6875\n","Epoch 4/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.8214 - accuracy: 0.7656 - val_loss: 0.8739 - val_accuracy: 0.7500\n","Epoch 5/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.7216 - accuracy: 0.7708 - val_loss: 0.8056 - val_accuracy: 0.7292\n","Epoch 6/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6242 - accuracy: 0.7865 - val_loss: 0.7608 - val_accuracy: 0.7292\n","Epoch 7/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.5496 - accuracy: 0.8021 - val_loss: 0.7504 - val_accuracy: 0.7708\n","Epoch 8/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4868 - accuracy: 0.8177 - val_loss: 0.7366 - val_accuracy: 0.7708\n","Epoch 9/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4566 - accuracy: 0.8125 - val_loss: 0.7503 - val_accuracy: 0.7708\n","Epoch 10/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8385 - val_loss: 0.7301 - val_accuracy: 0.7708\n","Epoch 11/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8177 - val_loss: 0.6980 - val_accuracy: 0.7708\n","Epoch 12/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3609 - accuracy: 0.8646 - val_loss: 0.7014 - val_accuracy: 0.7708\n","Epoch 13/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.8750 - val_loss: 0.6776 - val_accuracy: 0.7917\n","Epoch 14/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.8594 - val_loss: 0.6574 - val_accuracy: 0.7708\n","Epoch 15/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3047 - accuracy: 0.8594 - val_loss: 0.6755 - val_accuracy: 0.7917\n","Epoch 16/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2918 - accuracy: 0.8802 - val_loss: 0.6627 - val_accuracy: 0.7917\n","Epoch 17/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2769 - accuracy: 0.8906 - val_loss: 0.6357 - val_accuracy: 0.7917\n","Epoch 18/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2716 - accuracy: 0.8958 - val_loss: 0.6617 - val_accuracy: 0.7917\n","Epoch 19/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2581 - accuracy: 0.9010 - val_loss: 0.6397 - val_accuracy: 0.7917\n","Epoch 20/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2511 - accuracy: 0.9010 - val_loss: 0.6342 - val_accuracy: 0.7917\n","Epoch 21/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2403 - accuracy: 0.9115 - val_loss: 0.6616 - val_accuracy: 0.7917\n","Epoch 22/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2286 - accuracy: 0.9219 - val_loss: 0.6507 - val_accuracy: 0.7917\n","Epoch 23/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.2225 - accuracy: 0.9167 - val_loss: 0.6583 - val_accuracy: 0.7917\n","Epoch 24/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.2118 - accuracy: 0.9167 - val_loss: 0.6438 - val_accuracy: 0.7917\n","Epoch 25/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2076 - accuracy: 0.9115 - val_loss: 0.6613 - val_accuracy: 0.7917\n","Epoch 26/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2014 - accuracy: 0.9219 - val_loss: 0.6632 - val_accuracy: 0.7917\n","Epoch 27/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1995 - accuracy: 0.9375 - val_loss: 0.6542 - val_accuracy: 0.7917\n","Epoch 28/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.9271 - val_loss: 0.6884 - val_accuracy: 0.7917\n","Epoch 29/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1809 - accuracy: 0.9375 - val_loss: 0.6718 - val_accuracy: 0.7917\n","Epoch 30/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1754 - accuracy: 0.9375 - val_loss: 0.6611 - val_accuracy: 0.8125\n","Epoch 31/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9375 - val_loss: 0.7009 - val_accuracy: 0.7917\n","Epoch 32/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.1678 - accuracy: 0.9427 - val_loss: 0.7028 - val_accuracy: 0.7917\n","Epoch 33/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1614 - accuracy: 0.9427 - val_loss: 0.6848 - val_accuracy: 0.7917\n","Epoch 34/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9427 - val_loss: 0.7318 - val_accuracy: 0.7917\n","Epoch 35/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9323 - val_loss: 0.7101 - val_accuracy: 0.7708\n","Epoch 36/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1440 - accuracy: 0.9583 - val_loss: 0.6969 - val_accuracy: 0.7917\n","Epoch 37/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1398 - accuracy: 0.9583 - val_loss: 0.7362 - val_accuracy: 0.7917\n","Epoch 38/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9635 - val_loss: 0.7369 - val_accuracy: 0.7708\n","Epoch 39/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1326 - accuracy: 0.9583 - val_loss: 0.7265 - val_accuracy: 0.7917\n","Epoch 40/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1277 - accuracy: 0.9583 - val_loss: 0.7568 - val_accuracy: 0.7917\n","Epoch 41/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9688 - val_loss: 0.7475 - val_accuracy: 0.7708\n","Epoch 42/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9688 - val_loss: 0.7698 - val_accuracy: 0.7917\n","Epoch 43/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1141 - accuracy: 0.9688 - val_loss: 0.8029 - val_accuracy: 0.7708\n","Epoch 44/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1097 - accuracy: 0.9635 - val_loss: 0.7985 - val_accuracy: 0.7708\n","Epoch 45/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: 0.7722 - val_accuracy: 0.7917\n","Epoch 46/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.8146 - val_accuracy: 0.7708\n","Epoch 47/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 0.8152 - val_accuracy: 0.7708\n","Epoch 48/100\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0945 - accuracy: 0.9740 - val_loss: 0.8432 - val_accuracy: 0.7708\n","Epoch 49/100\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0900 - accuracy: 0.9792 - val_loss: 0.8526 - val_accuracy: 0.7708\n","Epoch 50/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.9740 - val_loss: 0.8541 - val_accuracy: 0.7708\n","Epoch 51/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0849 - accuracy: 0.9792 - val_loss: 0.8715 - val_accuracy: 0.7708\n","Epoch 52/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0803 - accuracy: 0.9792 - val_loss: 0.8540 - val_accuracy: 0.7917\n","Epoch 53/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 0.8865 - val_accuracy: 0.7708\n","Epoch 54/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0758 - accuracy: 0.9792 - val_loss: 0.8917 - val_accuracy: 0.7917\n","Epoch 55/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.9361 - val_accuracy: 0.7708\n","Epoch 56/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0743 - accuracy: 0.9740 - val_loss: 0.9301 - val_accuracy: 0.7917\n","Epoch 57/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9792 - val_loss: 0.9421 - val_accuracy: 0.7708\n","Epoch 58/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 0.9496 - val_accuracy: 0.7917\n","Epoch 59/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0634 - accuracy: 0.9896 - val_loss: 0.9460 - val_accuracy: 0.7917\n","Epoch 60/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0588 - accuracy: 0.9896 - val_loss: 0.9897 - val_accuracy: 0.7708\n","Epoch 61/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0582 - accuracy: 0.9844 - val_loss: 1.0255 - val_accuracy: 0.7708\n","Epoch 62/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0558 - accuracy: 0.9844 - val_loss: 1.0364 - val_accuracy: 0.7708\n","Epoch 63/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 1.0065 - val_accuracy: 0.7917\n","Epoch 64/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 1.0412 - val_accuracy: 0.7708\n","Epoch 65/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0515 - accuracy: 0.9896 - val_loss: 1.0415 - val_accuracy: 0.7917\n","Epoch 66/100\n","6/6 [==============================] - 0s 36ms/step - loss: 0.0493 - accuracy: 0.9896 - val_loss: 1.0580 - val_accuracy: 0.7917\n","Epoch 67/100\n","6/6 [==============================] - 0s 28ms/step - loss: 0.0460 - accuracy: 0.9896 - val_loss: 1.0940 - val_accuracy: 0.7917\n","Epoch 68/100\n","6/6 [==============================] - 0s 33ms/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 1.1143 - val_accuracy: 0.7917\n","Epoch 69/100\n","6/6 [==============================] - 0s 64ms/step - loss: 0.0438 - accuracy: 0.9948 - val_loss: 1.1022 - val_accuracy: 0.7917\n","Epoch 70/100\n","6/6 [==============================] - 0s 43ms/step - loss: 0.0419 - accuracy: 0.9948 - val_loss: 1.1200 - val_accuracy: 0.7708\n","Epoch 71/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0399 - accuracy: 0.9948 - val_loss: 1.1480 - val_accuracy: 0.7917\n","Epoch 72/100\n","6/6 [==============================] - 0s 26ms/step - loss: 0.0391 - accuracy: 0.9948 - val_loss: 1.1174 - val_accuracy: 0.7917\n","Epoch 73/100\n","6/6 [==============================] - 0s 39ms/step - loss: 0.0385 - accuracy: 0.9896 - val_loss: 1.1494 - val_accuracy: 0.7917\n","Epoch 74/100\n","6/6 [==============================] - 0s 36ms/step - loss: 0.0372 - accuracy: 0.9948 - val_loss: 1.1749 - val_accuracy: 0.7708\n","Epoch 75/100\n","6/6 [==============================] - 0s 30ms/step - loss: 0.0357 - accuracy: 0.9948 - val_loss: 1.1447 - val_accuracy: 0.7917\n","Epoch 76/100\n","6/6 [==============================] - 0s 30ms/step - loss: 0.0352 - accuracy: 0.9948 - val_loss: 1.2013 - val_accuracy: 0.7917\n","Epoch 77/100\n","6/6 [==============================] - 0s 26ms/step - loss: 0.0341 - accuracy: 0.9948 - val_loss: 1.1958 - val_accuracy: 0.7708\n","Epoch 78/100\n","6/6 [==============================] - 0s 34ms/step - loss: 0.0345 - accuracy: 0.9948 - val_loss: 1.1959 - val_accuracy: 0.7917\n","Epoch 79/100\n","6/6 [==============================] - 0s 33ms/step - loss: 0.0306 - accuracy: 0.9948 - val_loss: 1.1735 - val_accuracy: 0.7708\n","Epoch 80/100\n","6/6 [==============================] - 0s 45ms/step - loss: 0.0304 - accuracy: 0.9948 - val_loss: 1.1917 - val_accuracy: 0.7917\n","Epoch 81/100\n","6/6 [==============================] - 0s 30ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 1.2202 - val_accuracy: 0.7917\n","Epoch 82/100\n","6/6 [==============================] - 0s 21ms/step - loss: 0.0281 - accuracy: 0.9948 - val_loss: 1.2210 - val_accuracy: 0.7917\n","Epoch 83/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 0.9948 - val_loss: 1.2331 - val_accuracy: 0.7917\n","Epoch 84/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 1.2717 - val_accuracy: 0.7708\n","Epoch 85/100\n","6/6 [==============================] - 0s 23ms/step - loss: 0.0256 - accuracy: 0.9948 - val_loss: 1.2471 - val_accuracy: 0.7917\n","Epoch 86/100\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0252 - accuracy: 0.9948 - val_loss: 1.2723 - val_accuracy: 0.7917\n","Epoch 87/100\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 1.2387 - val_accuracy: 0.7917\n","Epoch 88/100\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0228 - accuracy: 0.9948 - val_loss: 1.2636 - val_accuracy: 0.7917\n","Epoch 89/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 1.2978 - val_accuracy: 0.7708\n","Epoch 90/100\n","6/6 [==============================] - 0s 34ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 1.2982 - val_accuracy: 0.7708\n","Epoch 91/100\n","6/6 [==============================] - 0s 27ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 1.3368 - val_accuracy: 0.7708\n","Epoch 92/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 1.3248 - val_accuracy: 0.7917\n","Epoch 93/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 1.3194 - val_accuracy: 0.7917\n","Epoch 94/100\n","6/6 [==============================] - 0s 28ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 1.3375 - val_accuracy: 0.7708\n","Epoch 95/100\n","6/6 [==============================] - 0s 35ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 1.3241 - val_accuracy: 0.7917\n","Epoch 96/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.3212 - val_accuracy: 0.8125\n","Epoch 97/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.3491 - val_accuracy: 0.7917\n","Epoch 98/100\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.3453 - val_accuracy: 0.7917\n","Epoch 99/100\n","6/6 [==============================] - 0s 36ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.3347 - val_accuracy: 0.7917\n","Epoch 100/100\n","6/6 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 1.3662 - val_accuracy: 0.7917\n","Loss: 0.9377440810203552, Accuracy: 0.8333333134651184\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load the dataset\n","data = pd.read_csv('/content/synthetic_iris_like_data.csv')\n","\n","# Separate features and labels\n","X = data.drop(columns=['class']).values\n","y = data['class'].values\n","\n","# One-hot encode the labels\n","y = to_categorical(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(y.shape[1], activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","print(f'Loss: {loss}, Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t83tdFkpV21t","executionInfo":{"status":"ok","timestamp":1718479221695,"user_tz":420,"elapsed":11848,"user":{"displayName":"Dan Sullivan","userId":"04950569771201204395"}},"outputId":"c93eea58-b385-4f44-fa7f-6042fef62cdb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","6/6 [==============================] - 1s 47ms/step - loss: 1.0531 - accuracy: 0.5208 - val_loss: 1.0151 - val_accuracy: 0.6667\n","Epoch 2/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.9185 - accuracy: 0.7812 - val_loss: 0.9131 - val_accuracy: 0.7083\n","Epoch 3/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.7646 - accuracy: 0.7969 - val_loss: 0.7794 - val_accuracy: 0.7500\n","Epoch 4/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.5987 - accuracy: 0.8177 - val_loss: 0.6866 - val_accuracy: 0.7708\n","Epoch 5/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4842 - accuracy: 0.8385 - val_loss: 0.6746 - val_accuracy: 0.7708\n","Epoch 6/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4099 - accuracy: 0.8229 - val_loss: 0.7149 - val_accuracy: 0.7708\n","Epoch 7/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.8542 - val_loss: 0.7082 - val_accuracy: 0.7917\n","Epoch 8/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.8542 - val_loss: 0.6607 - val_accuracy: 0.7708\n","Epoch 9/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.2894 - accuracy: 0.8906 - val_loss: 0.6657 - val_accuracy: 0.7708\n","Epoch 10/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.2641 - accuracy: 0.8958 - val_loss: 0.6468 - val_accuracy: 0.7708\n","Epoch 11/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.9010 - val_loss: 0.6374 - val_accuracy: 0.7917\n","Epoch 12/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 0.9010 - val_loss: 0.6232 - val_accuracy: 0.7708\n","Epoch 13/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9167 - val_loss: 0.6794 - val_accuracy: 0.7917\n","Epoch 14/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2082 - accuracy: 0.9167 - val_loss: 0.6648 - val_accuracy: 0.7917\n","Epoch 15/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.2060 - accuracy: 0.9010 - val_loss: 0.7146 - val_accuracy: 0.7917\n","Epoch 16/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1911 - accuracy: 0.9219 - val_loss: 0.7203 - val_accuracy: 0.7917\n","Epoch 17/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.9375 - val_loss: 0.6732 - val_accuracy: 0.7917\n","Epoch 18/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.9219 - val_loss: 0.6737 - val_accuracy: 0.7708\n","Epoch 19/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1664 - accuracy: 0.9323 - val_loss: 0.7722 - val_accuracy: 0.7917\n","Epoch 20/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9271 - val_loss: 0.7243 - val_accuracy: 0.7917\n","Epoch 21/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 0.9427 - val_loss: 0.7385 - val_accuracy: 0.7708\n","Epoch 22/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.9479 - val_loss: 0.7592 - val_accuracy: 0.7917\n","Epoch 23/100\n","6/6 [==============================] - 0s 21ms/step - loss: 0.1249 - accuracy: 0.9531 - val_loss: 0.7338 - val_accuracy: 0.7708\n","Epoch 24/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9740 - val_loss: 0.7935 - val_accuracy: 0.7917\n","Epoch 25/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.1070 - accuracy: 0.9688 - val_loss: 0.8077 - val_accuracy: 0.7917\n","Epoch 26/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9792 - val_loss: 0.8048 - val_accuracy: 0.8125\n","Epoch 27/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9688 - val_loss: 0.8311 - val_accuracy: 0.7917\n","Epoch 28/100\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0968 - accuracy: 0.9688 - val_loss: 0.8951 - val_accuracy: 0.7917\n","Epoch 29/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9635 - val_loss: 0.9051 - val_accuracy: 0.7708\n","Epoch 30/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9688 - val_loss: 0.8501 - val_accuracy: 0.7708\n","Epoch 31/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.9353 - val_accuracy: 0.7917\n","Epoch 32/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9740 - val_loss: 0.9123 - val_accuracy: 0.7708\n","Epoch 33/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9740 - val_loss: 0.9839 - val_accuracy: 0.7917\n","Epoch 34/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0659 - accuracy: 0.9844 - val_loss: 0.9345 - val_accuracy: 0.7500\n","Epoch 35/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 1.0008 - val_accuracy: 0.7917\n","Epoch 36/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 1.0360 - val_accuracy: 0.7708\n","Epoch 37/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0535 - accuracy: 0.9792 - val_loss: 1.0410 - val_accuracy: 0.7708\n","Epoch 38/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 1.0464 - val_accuracy: 0.7708\n","Epoch 39/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0472 - accuracy: 0.9896 - val_loss: 1.0642 - val_accuracy: 0.7708\n","Epoch 40/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0450 - accuracy: 0.9792 - val_loss: 1.1694 - val_accuracy: 0.7917\n","Epoch 41/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 1.1325 - val_accuracy: 0.7708\n","Epoch 42/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 1.1029 - val_accuracy: 0.7708\n","Epoch 43/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9844 - val_loss: 1.2195 - val_accuracy: 0.7917\n","Epoch 44/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0377 - accuracy: 0.9844 - val_loss: 1.1826 - val_accuracy: 0.7500\n","Epoch 45/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9844 - val_loss: 1.2199 - val_accuracy: 0.7708\n","Epoch 46/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9844 - val_loss: 1.2571 - val_accuracy: 0.7708\n","Epoch 47/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 1.3373 - val_accuracy: 0.7917\n","Epoch 48/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 1.3529 - val_accuracy: 0.7708\n","Epoch 49/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9792 - val_loss: 1.2488 - val_accuracy: 0.7708\n","Epoch 50/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 1.4379 - val_accuracy: 0.7917\n","Epoch 51/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9948 - val_loss: 1.2726 - val_accuracy: 0.7708\n","Epoch 52/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 1.2665 - val_accuracy: 0.7500\n","Epoch 53/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.7708\n","Epoch 54/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 1.4484 - val_accuracy: 0.7917\n","Epoch 55/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.4622 - val_accuracy: 0.7500\n","Epoch 56/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 1.5127 - val_accuracy: 0.7917\n","Epoch 57/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.3837 - val_accuracy: 0.7917\n","Epoch 58/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.4373 - val_accuracy: 0.7917\n","Epoch 59/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 1.5234 - val_accuracy: 0.7708\n","Epoch 60/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 1.5309 - val_accuracy: 0.7917\n","Epoch 61/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.7917\n","Epoch 62/100\n","6/6 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5350 - val_accuracy: 0.7708\n","Epoch 63/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.7917\n","Epoch 64/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.5940 - val_accuracy: 0.7708\n","Epoch 65/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5942 - val_accuracy: 0.7917\n","Epoch 66/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6230 - val_accuracy: 0.7917\n","Epoch 67/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6573 - val_accuracy: 0.7917\n","Epoch 68/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.7917\n","Epoch 69/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6913 - val_accuracy: 0.7917\n","Epoch 70/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7097 - val_accuracy: 0.7917\n","Epoch 71/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7497 - val_accuracy: 0.7917\n","Epoch 72/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7302 - val_accuracy: 0.7917\n","Epoch 73/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.7917\n","Epoch 74/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7890 - val_accuracy: 0.7917\n","Epoch 75/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.7917\n","Epoch 76/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.7917\n","Epoch 77/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8156 - val_accuracy: 0.7917\n","Epoch 78/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.8350 - val_accuracy: 0.7917\n","Epoch 79/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8626 - val_accuracy: 0.7917\n","Epoch 80/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.7917\n","Epoch 81/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.7917\n","Epoch 82/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8869 - val_accuracy: 0.7917\n","Epoch 83/100\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8836 - val_accuracy: 0.7917\n","Epoch 84/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.8994 - val_accuracy: 0.7917\n","Epoch 85/100\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9185 - val_accuracy: 0.7917\n","Epoch 86/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9254 - val_accuracy: 0.7917\n","Epoch 87/100\n","6/6 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9235 - val_accuracy: 0.7917\n","Epoch 88/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9437 - val_accuracy: 0.7917\n","Epoch 89/100\n","6/6 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9485 - val_accuracy: 0.7917\n","Epoch 90/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9580 - val_accuracy: 0.7917\n","Epoch 91/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.7917\n","Epoch 92/100\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9853 - val_accuracy: 0.7917\n","Epoch 93/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9761 - val_accuracy: 0.7917\n","Epoch 94/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9845 - val_accuracy: 0.7917\n","Epoch 95/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.7917\n","Epoch 96/100\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0058 - val_accuracy: 0.7917\n","Epoch 97/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0277 - val_accuracy: 0.7917\n","Epoch 98/100\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0264 - val_accuracy: 0.7917\n","Epoch 99/100\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0216 - val_accuracy: 0.7917\n","Epoch 100/100\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0348 - val_accuracy: 0.8125\n","Loss: 1.1671874523162842, Accuracy: 0.8500000238418579\n"]}]}]}